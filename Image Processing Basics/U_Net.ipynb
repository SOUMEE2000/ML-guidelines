{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net.ipynb",
      "provenance": [],
      "mount_file_id": "1VMaObEzEJxKTxJJPasKuhNJ6FkEVm1Rx",
      "authorship_tag": "ABX9TyO2QfJsOW4k6AASC+S1xUR8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SOUMEE2000/Machine-Learning-Stash/blob/main/Image%20Processing%20Basics/U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NihXpX6BgQQp"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models  import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQwEyHxHi3ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5c97fb-c606-486c-e7e1-b193f099f2ba"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "\n",
        "#Build the model\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "#s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "#Contraction path\n",
        "#c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "#c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "#c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "#p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "c2 = tf.keras.layers.Dropout(0.2)(c2)\n",
        "c2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "c3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "c4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "c5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "p5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c5)\n",
        "\n",
        "c5_n = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p5)\n",
        "c5_n = tf.keras.layers.Dropout(0.3)(c5_n)\n",
        "c5_n = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5_n)\n",
        "\n",
        "\n",
        "#Expansive path \n",
        "u6_n = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5_n)\n",
        "u6_n = tf.keras.layers.concatenate([u6_n, c5])\n",
        "c6_n = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6_n)\n",
        "c6_n = tf.keras.layers.Dropout(0.2)(c6_n)\n",
        "c6_n = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6_n)\n",
        " \n",
        "\n",
        "u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "c7 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u7)\n",
        "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "c7 = tf.keras.layers.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\n",
        " \n",
        "u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "c8 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u8)\n",
        "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "c8 = tf.keras.layers.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\n",
        " \n",
        "#u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "#u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "#c9 = tf.keras.layers.Conv2D(16, (3, 3), kernel_initializer='he_normal', padding='same')(u9)\n",
        "#c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "#c9 = tf.keras.layers.Conv2D(16, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c8)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "adam = Adam(0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256, 256, 64) 0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128, 128, 128 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64, 64, 256)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 512)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 256)  524544      conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 64, 64, 256)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 256)  590080      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 131200      conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128, 128, 128 0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 128 147584      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 32832       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 256, 256, 64) 0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 256, 256, 64) 36928       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 1)  65          conv2d_17[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 7,697,345\n",
            "Trainable params: 7,697,345\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtHH3wtLdEzg",
        "outputId": "78e1306e-a04c-4c12-99c3-eac17afb8456"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/Datasets/DRIVE.zip\"\n",
        "with ZipFile(file_name,'r') as zipf:\n",
        "  zipf.extractall()\n",
        "  print('finish')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEl8o0R6FQij"
      },
      "source": [
        "import os\n",
        "\n",
        "import cv2\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "#import  scipy.misc.pilutil\n",
        "data_location = ''\n",
        "\n",
        "training_loc= \"/content/DRIVE/training/images/\"\n",
        "training_label_loc= \"/content/DRIVE/training/1st_manual/\"\n",
        "#training_loc_mask= \"/content/DRIVE/training/mask/\"\n",
        "\n",
        "training_images= os.listdir(training_loc)\n",
        "training_labels= os.listdir(training_label_loc)\n",
        "#training_masks= os.listdir(training_loc_mask)\n",
        "\n",
        "training_images.sort()\n",
        "training_labels.sort()\n",
        "\n",
        "train_data = []\n",
        "train_label = []\n",
        "desired_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjqfQk4oDPXp"
      },
      "source": [
        "for i in training_images:\n",
        "    im = plt.imread(training_loc + i)\n",
        "    label = plt.imread(training_label_loc + i.split('_')[0] + '_manual1.gif')\n",
        "    train_data.append(cv2.resize(im, (desired_size, desired_size)))\n",
        "    temp = cv2.resize(label, (desired_size, desired_size))\n",
        "    train_label.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBZ4GYlpSps2",
        "outputId": "f8c58e34-107a-4448-f8e8-03b40d26448e"
      },
      "source": [
        "np.array(train_label).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9layl_YgJ6lK"
      },
      "source": [
        "train_label = np.array(train_label)\n",
        "train_label = np.reshape(train_label, (20,desired_size, desired_size,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6aYEmHiTA7A"
      },
      "source": [
        "train_data = np.array(train_data)\n",
        "\n",
        "x_train = train_data.astype('float32') / 255.\n",
        "y_train = train_label.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X-vVPCIYE0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72962906-4d6a-48f4-ba74-3b1dc149cfec"
      },
      "source": [
        "model.fit( x_train, y_train, steps_per_epoch=10, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "10/10 [==============================] - 36s 96ms/step - loss: 0.5726 - accuracy: 0.8265\n",
            "Epoch 2/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.4662 - accuracy: 0.8654\n",
            "Epoch 3/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.4015 - accuracy: 0.8770\n",
            "Epoch 4/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.3142 - accuracy: 0.8778\n",
            "Epoch 5/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.2856 - accuracy: 0.8789\n",
            "Epoch 6/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.2801 - accuracy: 0.8793\n",
            "Epoch 7/1000\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 0.2773 - accuracy: 0.8792\n",
            "Epoch 8/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2770 - accuracy: 0.8792\n",
            "Epoch 9/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2751 - accuracy: 0.8794\n",
            "Epoch 10/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2709 - accuracy: 0.8795\n",
            "Epoch 11/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2684 - accuracy: 0.8795\n",
            "Epoch 12/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2667 - accuracy: 0.8795\n",
            "Epoch 13/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.2653 - accuracy: 0.8795\n",
            "Epoch 14/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2636 - accuracy: 0.8795\n",
            "Epoch 15/1000\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.2626 - accuracy: 0.8795\n",
            "Epoch 16/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.2601 - accuracy: 0.8795\n",
            "Epoch 17/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.2597 - accuracy: 0.8795\n",
            "Epoch 18/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.2570 - accuracy: 0.8795\n",
            "Epoch 19/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.2599 - accuracy: 0.8795\n",
            "Epoch 20/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.2634 - accuracy: 0.8795\n",
            "Epoch 21/1000\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 0.2570 - accuracy: 0.8795\n",
            "Epoch 22/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.2571 - accuracy: 0.8795\n",
            "Epoch 23/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.2557 - accuracy: 0.8795\n",
            "Epoch 24/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.2523 - accuracy: 0.8795\n",
            "Epoch 25/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.2490 - accuracy: 0.8796\n",
            "Epoch 26/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.2459 - accuracy: 0.8798\n",
            "Epoch 27/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.2427 - accuracy: 0.8800\n",
            "Epoch 28/1000\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 0.2444 - accuracy: 0.8804\n",
            "Epoch 29/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.2412 - accuracy: 0.8807\n",
            "Epoch 30/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.2379 - accuracy: 0.8811\n",
            "Epoch 31/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.2352 - accuracy: 0.8820\n",
            "Epoch 32/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.2302 - accuracy: 0.8829\n",
            "Epoch 33/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.2274 - accuracy: 0.8841\n",
            "Epoch 34/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.2317 - accuracy: 0.8845\n",
            "Epoch 35/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.2339 - accuracy: 0.8836\n",
            "Epoch 36/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.2276 - accuracy: 0.8843\n",
            "Epoch 37/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.2244 - accuracy: 0.8851\n",
            "Epoch 38/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2209 - accuracy: 0.8862\n",
            "Epoch 39/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2169 - accuracy: 0.8875\n",
            "Epoch 40/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2231 - accuracy: 0.8863\n",
            "Epoch 41/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.2216 - accuracy: 0.8863\n",
            "Epoch 42/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.2147 - accuracy: 0.8886\n",
            "Epoch 43/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.2142 - accuracy: 0.8890\n",
            "Epoch 44/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2104 - accuracy: 0.8897\n",
            "Epoch 45/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.2197 - accuracy: 0.8874\n",
            "Epoch 46/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2242 - accuracy: 0.8862\n",
            "Epoch 47/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2098 - accuracy: 0.8902\n",
            "Epoch 48/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.2114 - accuracy: 0.8896\n",
            "Epoch 49/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2096 - accuracy: 0.8893\n",
            "Epoch 50/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2047 - accuracy: 0.8918\n",
            "Epoch 51/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.2031 - accuracy: 0.8928\n",
            "Epoch 52/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.2005 - accuracy: 0.8927\n",
            "Epoch 53/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.1987 - accuracy: 0.8934\n",
            "Epoch 54/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.1987 - accuracy: 0.8934\n",
            "Epoch 55/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.1975 - accuracy: 0.8940\n",
            "Epoch 56/1000\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.1963 - accuracy: 0.8947\n",
            "Epoch 57/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1950 - accuracy: 0.8947\n",
            "Epoch 58/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1935 - accuracy: 0.8949\n",
            "Epoch 59/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1935 - accuracy: 0.8957\n",
            "Epoch 60/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1924 - accuracy: 0.8958\n",
            "Epoch 61/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1919 - accuracy: 0.8952\n",
            "Epoch 62/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1927 - accuracy: 0.8956\n",
            "Epoch 63/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1899 - accuracy: 0.8968\n",
            "Epoch 64/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1875 - accuracy: 0.8971\n",
            "Epoch 65/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1911 - accuracy: 0.8962\n",
            "Epoch 66/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1992 - accuracy: 0.8945\n",
            "Epoch 67/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1893 - accuracy: 0.8981\n",
            "Epoch 68/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1892 - accuracy: 0.8965\n",
            "Epoch 69/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1877 - accuracy: 0.8975\n",
            "Epoch 70/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1837 - accuracy: 0.8986\n",
            "Epoch 71/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1853 - accuracy: 0.8984\n",
            "Epoch 72/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1852 - accuracy: 0.8989\n",
            "Epoch 73/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1853 - accuracy: 0.8989\n",
            "Epoch 74/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1821 - accuracy: 0.8988\n",
            "Epoch 75/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1843 - accuracy: 0.8998\n",
            "Epoch 76/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1822 - accuracy: 0.8988\n",
            "Epoch 77/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1843 - accuracy: 0.8996\n",
            "Epoch 78/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1809 - accuracy: 0.8999\n",
            "Epoch 79/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1804 - accuracy: 0.8997\n",
            "Epoch 80/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1777 - accuracy: 0.9009\n",
            "Epoch 81/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1783 - accuracy: 0.9009\n",
            "Epoch 82/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1799 - accuracy: 0.9001\n",
            "Epoch 83/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1770 - accuracy: 0.9020\n",
            "Epoch 84/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1769 - accuracy: 0.9008\n",
            "Epoch 85/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1751 - accuracy: 0.9017\n",
            "Epoch 86/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1734 - accuracy: 0.9020\n",
            "Epoch 87/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1712 - accuracy: 0.9031\n",
            "Epoch 88/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1716 - accuracy: 0.9029\n",
            "Epoch 89/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1721 - accuracy: 0.9024\n",
            "Epoch 90/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1705 - accuracy: 0.9035\n",
            "Epoch 91/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1689 - accuracy: 0.9033\n",
            "Epoch 92/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1673 - accuracy: 0.9034\n",
            "Epoch 93/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1683 - accuracy: 0.9042\n",
            "Epoch 94/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1682 - accuracy: 0.9041\n",
            "Epoch 95/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1714 - accuracy: 0.9035\n",
            "Epoch 96/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1801 - accuracy: 0.9024\n",
            "Epoch 97/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1757 - accuracy: 0.9033\n",
            "Epoch 98/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1685 - accuracy: 0.9044\n",
            "Epoch 99/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1670 - accuracy: 0.9038\n",
            "Epoch 100/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1682 - accuracy: 0.9047\n",
            "Epoch 101/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1676 - accuracy: 0.9051\n",
            "Epoch 102/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1634 - accuracy: 0.9058\n",
            "Epoch 103/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1620 - accuracy: 0.9057\n",
            "Epoch 104/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1624 - accuracy: 0.9059\n",
            "Epoch 105/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1636 - accuracy: 0.9054\n",
            "Epoch 106/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1605 - accuracy: 0.9060\n",
            "Epoch 107/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1594 - accuracy: 0.9065\n",
            "Epoch 108/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1582 - accuracy: 0.9069\n",
            "Epoch 109/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1579 - accuracy: 0.9069\n",
            "Epoch 110/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1593 - accuracy: 0.9066\n",
            "Epoch 111/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1631 - accuracy: 0.9067\n",
            "Epoch 112/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1605 - accuracy: 0.9070\n",
            "Epoch 113/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1603 - accuracy: 0.9064\n",
            "Epoch 114/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1565 - accuracy: 0.9072\n",
            "Epoch 115/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1555 - accuracy: 0.9082\n",
            "Epoch 116/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1556 - accuracy: 0.9083\n",
            "Epoch 117/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1541 - accuracy: 0.9081\n",
            "Epoch 118/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1530 - accuracy: 0.9090\n",
            "Epoch 119/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1549 - accuracy: 0.9086\n",
            "Epoch 120/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1531 - accuracy: 0.9089\n",
            "Epoch 121/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1518 - accuracy: 0.9094\n",
            "Epoch 122/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1515 - accuracy: 0.9091\n",
            "Epoch 123/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1504 - accuracy: 0.9094\n",
            "Epoch 124/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1504 - accuracy: 0.9097\n",
            "Epoch 125/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1491 - accuracy: 0.9102\n",
            "Epoch 126/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1498 - accuracy: 0.9100\n",
            "Epoch 127/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1501 - accuracy: 0.9098\n",
            "Epoch 128/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1495 - accuracy: 0.9101\n",
            "Epoch 129/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1478 - accuracy: 0.9106\n",
            "Epoch 130/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1500 - accuracy: 0.9097\n",
            "Epoch 131/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1496 - accuracy: 0.9100\n",
            "Epoch 132/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1503 - accuracy: 0.9100\n",
            "Epoch 133/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1482 - accuracy: 0.9105\n",
            "Epoch 134/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1486 - accuracy: 0.9110\n",
            "Epoch 135/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1466 - accuracy: 0.9114\n",
            "Epoch 136/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1456 - accuracy: 0.9110\n",
            "Epoch 137/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1452 - accuracy: 0.9114\n",
            "Epoch 138/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1451 - accuracy: 0.9115\n",
            "Epoch 139/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1449 - accuracy: 0.9113\n",
            "Epoch 140/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1438 - accuracy: 0.9117\n",
            "Epoch 141/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1445 - accuracy: 0.9119\n",
            "Epoch 142/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1427 - accuracy: 0.9121\n",
            "Epoch 143/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1434 - accuracy: 0.9120\n",
            "Epoch 144/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1415 - accuracy: 0.9125\n",
            "Epoch 145/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1418 - accuracy: 0.9123\n",
            "Epoch 146/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1417 - accuracy: 0.9125\n",
            "Epoch 147/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1436 - accuracy: 0.9118\n",
            "Epoch 148/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1446 - accuracy: 0.9117\n",
            "Epoch 149/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1464 - accuracy: 0.9120\n",
            "Epoch 150/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1442 - accuracy: 0.9122\n",
            "Epoch 151/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1416 - accuracy: 0.9123\n",
            "Epoch 152/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1405 - accuracy: 0.9128\n",
            "Epoch 153/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1389 - accuracy: 0.9132\n",
            "Epoch 154/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1380 - accuracy: 0.9134\n",
            "Epoch 155/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1369 - accuracy: 0.9140\n",
            "Epoch 156/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1369 - accuracy: 0.9137\n",
            "Epoch 157/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1367 - accuracy: 0.9139\n",
            "Epoch 158/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1361 - accuracy: 0.9142\n",
            "Epoch 159/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1349 - accuracy: 0.9144\n",
            "Epoch 160/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1350 - accuracy: 0.9145\n",
            "Epoch 161/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1388 - accuracy: 0.9132\n",
            "Epoch 162/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1404 - accuracy: 0.9131\n",
            "Epoch 163/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1416 - accuracy: 0.9129\n",
            "Epoch 164/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1398 - accuracy: 0.9127\n",
            "Epoch 165/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1385 - accuracy: 0.9133\n",
            "Epoch 166/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1360 - accuracy: 0.9140\n",
            "Epoch 167/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1348 - accuracy: 0.9146\n",
            "Epoch 168/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1337 - accuracy: 0.9147\n",
            "Epoch 169/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1326 - accuracy: 0.9151\n",
            "Epoch 170/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1325 - accuracy: 0.9151\n",
            "Epoch 171/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1319 - accuracy: 0.9155\n",
            "Epoch 172/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1311 - accuracy: 0.9153\n",
            "Epoch 173/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1311 - accuracy: 0.9157\n",
            "Epoch 174/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1311 - accuracy: 0.9154\n",
            "Epoch 175/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1299 - accuracy: 0.9157\n",
            "Epoch 176/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1313 - accuracy: 0.9156\n",
            "Epoch 177/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1310 - accuracy: 0.9154\n",
            "Epoch 178/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1293 - accuracy: 0.9162\n",
            "Epoch 179/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1289 - accuracy: 0.9160\n",
            "Epoch 180/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1298 - accuracy: 0.9157\n",
            "Epoch 181/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1285 - accuracy: 0.9161\n",
            "Epoch 182/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1274 - accuracy: 0.9165\n",
            "Epoch 183/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1267 - accuracy: 0.9166\n",
            "Epoch 184/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1274 - accuracy: 0.9166\n",
            "Epoch 185/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1268 - accuracy: 0.9167\n",
            "Epoch 186/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1255 - accuracy: 0.9170\n",
            "Epoch 187/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1270 - accuracy: 0.9168\n",
            "Epoch 188/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1252 - accuracy: 0.9170\n",
            "Epoch 189/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1251 - accuracy: 0.9169\n",
            "Epoch 190/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1269 - accuracy: 0.9167\n",
            "Epoch 191/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1279 - accuracy: 0.9164\n",
            "Epoch 192/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1255 - accuracy: 0.9172\n",
            "Epoch 193/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1245 - accuracy: 0.9171\n",
            "Epoch 194/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1239 - accuracy: 0.9176\n",
            "Epoch 195/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1234 - accuracy: 0.9174\n",
            "Epoch 196/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1226 - accuracy: 0.9177\n",
            "Epoch 197/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1227 - accuracy: 0.9176\n",
            "Epoch 198/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1226 - accuracy: 0.9177\n",
            "Epoch 199/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1219 - accuracy: 0.9178\n",
            "Epoch 200/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1214 - accuracy: 0.9176\n",
            "Epoch 201/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1215 - accuracy: 0.9178\n",
            "Epoch 202/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1208 - accuracy: 0.9181\n",
            "Epoch 203/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1196 - accuracy: 0.9183\n",
            "Epoch 204/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1201 - accuracy: 0.9183\n",
            "Epoch 205/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1205 - accuracy: 0.9185\n",
            "Epoch 206/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1190 - accuracy: 0.9186\n",
            "Epoch 207/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1186 - accuracy: 0.9186\n",
            "Epoch 208/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1184 - accuracy: 0.9186\n",
            "Epoch 209/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1181 - accuracy: 0.9189\n",
            "Epoch 210/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1186 - accuracy: 0.9188\n",
            "Epoch 211/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1194 - accuracy: 0.9184\n",
            "Epoch 212/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1195 - accuracy: 0.9184\n",
            "Epoch 213/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1192 - accuracy: 0.9181\n",
            "Epoch 214/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1197 - accuracy: 0.9184\n",
            "Epoch 215/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1185 - accuracy: 0.9184\n",
            "Epoch 216/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1176 - accuracy: 0.9189\n",
            "Epoch 217/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1165 - accuracy: 0.9190\n",
            "Epoch 218/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1157 - accuracy: 0.9192\n",
            "Epoch 219/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1145 - accuracy: 0.9196\n",
            "Epoch 220/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1144 - accuracy: 0.9197\n",
            "Epoch 221/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1140 - accuracy: 0.9196\n",
            "Epoch 222/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1129 - accuracy: 0.9199\n",
            "Epoch 223/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1134 - accuracy: 0.9197\n",
            "Epoch 224/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1129 - accuracy: 0.9198\n",
            "Epoch 225/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.1130 - accuracy: 0.9198\n",
            "Epoch 226/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1125 - accuracy: 0.9199\n",
            "Epoch 227/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1123 - accuracy: 0.9200\n",
            "Epoch 228/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1118 - accuracy: 0.9200\n",
            "Epoch 229/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1115 - accuracy: 0.9203\n",
            "Epoch 230/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1117 - accuracy: 0.9201\n",
            "Epoch 231/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1111 - accuracy: 0.9203\n",
            "Epoch 232/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1100 - accuracy: 0.9206\n",
            "Epoch 233/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1107 - accuracy: 0.9202\n",
            "Epoch 234/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1100 - accuracy: 0.9204\n",
            "Epoch 235/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1089 - accuracy: 0.9207\n",
            "Epoch 236/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1085 - accuracy: 0.9208\n",
            "Epoch 237/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1083 - accuracy: 0.9210\n",
            "Epoch 238/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1080 - accuracy: 0.9208\n",
            "Epoch 239/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1078 - accuracy: 0.9211\n",
            "Epoch 240/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1077 - accuracy: 0.9209\n",
            "Epoch 241/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.1075 - accuracy: 0.9209\n",
            "Epoch 242/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1070 - accuracy: 0.9212\n",
            "Epoch 243/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1064 - accuracy: 0.9212\n",
            "Epoch 244/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1057 - accuracy: 0.9213\n",
            "Epoch 245/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1056 - accuracy: 0.9215\n",
            "Epoch 246/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1056 - accuracy: 0.9213\n",
            "Epoch 247/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1055 - accuracy: 0.9213\n",
            "Epoch 248/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1051 - accuracy: 0.9215\n",
            "Epoch 249/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1060 - accuracy: 0.9213\n",
            "Epoch 250/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1051 - accuracy: 0.9215\n",
            "Epoch 251/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1048 - accuracy: 0.9217\n",
            "Epoch 252/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1040 - accuracy: 0.9217\n",
            "Epoch 253/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1034 - accuracy: 0.9218\n",
            "Epoch 254/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.1029 - accuracy: 0.9220\n",
            "Epoch 255/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1025 - accuracy: 0.9220\n",
            "Epoch 256/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1028 - accuracy: 0.9220\n",
            "Epoch 257/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1014 - accuracy: 0.9222\n",
            "Epoch 258/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1012 - accuracy: 0.9222\n",
            "Epoch 259/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1008 - accuracy: 0.9225\n",
            "Epoch 260/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.1009 - accuracy: 0.9222\n",
            "Epoch 261/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.1002 - accuracy: 0.9225\n",
            "Epoch 262/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0999 - accuracy: 0.9226\n",
            "Epoch 263/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0996 - accuracy: 0.9225\n",
            "Epoch 264/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0994 - accuracy: 0.9226\n",
            "Epoch 265/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0992 - accuracy: 0.9228\n",
            "Epoch 266/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0984 - accuracy: 0.9228\n",
            "Epoch 267/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0988 - accuracy: 0.9227\n",
            "Epoch 268/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0993 - accuracy: 0.9226\n",
            "Epoch 269/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0983 - accuracy: 0.9227\n",
            "Epoch 270/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0975 - accuracy: 0.9230\n",
            "Epoch 271/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0977 - accuracy: 0.9230\n",
            "Epoch 272/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0972 - accuracy: 0.9230\n",
            "Epoch 273/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0966 - accuracy: 0.9231\n",
            "Epoch 274/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0971 - accuracy: 0.9229\n",
            "Epoch 275/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0965 - accuracy: 0.9231\n",
            "Epoch 276/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0962 - accuracy: 0.9232\n",
            "Epoch 277/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0957 - accuracy: 0.9233\n",
            "Epoch 278/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0952 - accuracy: 0.9234\n",
            "Epoch 279/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0950 - accuracy: 0.9235\n",
            "Epoch 280/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0950 - accuracy: 0.9234\n",
            "Epoch 281/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0946 - accuracy: 0.9235\n",
            "Epoch 282/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0947 - accuracy: 0.9236\n",
            "Epoch 283/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0945 - accuracy: 0.9236\n",
            "Epoch 284/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0941 - accuracy: 0.9236\n",
            "Epoch 285/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0938 - accuracy: 0.9236\n",
            "Epoch 286/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0939 - accuracy: 0.9236\n",
            "Epoch 287/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0933 - accuracy: 0.9236\n",
            "Epoch 288/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0928 - accuracy: 0.9238\n",
            "Epoch 289/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0922 - accuracy: 0.9239\n",
            "Epoch 290/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0918 - accuracy: 0.9241\n",
            "Epoch 291/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0920 - accuracy: 0.9239\n",
            "Epoch 292/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0912 - accuracy: 0.9241\n",
            "Epoch 293/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0915 - accuracy: 0.9240\n",
            "Epoch 294/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0915 - accuracy: 0.9241\n",
            "Epoch 295/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0910 - accuracy: 0.9241\n",
            "Epoch 296/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0906 - accuracy: 0.9243\n",
            "Epoch 297/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0903 - accuracy: 0.9244\n",
            "Epoch 298/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0900 - accuracy: 0.9243\n",
            "Epoch 299/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0895 - accuracy: 0.9245\n",
            "Epoch 300/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0897 - accuracy: 0.9243\n",
            "Epoch 301/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0895 - accuracy: 0.9243\n",
            "Epoch 302/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0892 - accuracy: 0.9244\n",
            "Epoch 303/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0888 - accuracy: 0.9245\n",
            "Epoch 304/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0885 - accuracy: 0.9246\n",
            "Epoch 305/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0882 - accuracy: 0.9246\n",
            "Epoch 306/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0881 - accuracy: 0.9247\n",
            "Epoch 307/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0881 - accuracy: 0.9247\n",
            "Epoch 308/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0878 - accuracy: 0.9247\n",
            "Epoch 309/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0883 - accuracy: 0.9246\n",
            "Epoch 310/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0881 - accuracy: 0.9247\n",
            "Epoch 311/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0887 - accuracy: 0.9245\n",
            "Epoch 312/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0879 - accuracy: 0.9247\n",
            "Epoch 313/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0879 - accuracy: 0.9247\n",
            "Epoch 314/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0873 - accuracy: 0.9248\n",
            "Epoch 315/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0870 - accuracy: 0.9248\n",
            "Epoch 316/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0864 - accuracy: 0.9249\n",
            "Epoch 317/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0857 - accuracy: 0.9251\n",
            "Epoch 318/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0857 - accuracy: 0.9251\n",
            "Epoch 319/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0855 - accuracy: 0.9251\n",
            "Epoch 320/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0849 - accuracy: 0.9253\n",
            "Epoch 321/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0845 - accuracy: 0.9254\n",
            "Epoch 322/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0847 - accuracy: 0.9254\n",
            "Epoch 323/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0851 - accuracy: 0.9253\n",
            "Epoch 324/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0853 - accuracy: 0.9252\n",
            "Epoch 325/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0845 - accuracy: 0.9254\n",
            "Epoch 326/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0839 - accuracy: 0.9255\n",
            "Epoch 327/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0836 - accuracy: 0.9254\n",
            "Epoch 328/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0831 - accuracy: 0.9255\n",
            "Epoch 329/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0833 - accuracy: 0.9257\n",
            "Epoch 330/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0833 - accuracy: 0.9255\n",
            "Epoch 331/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0830 - accuracy: 0.9256\n",
            "Epoch 332/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0833 - accuracy: 0.9257\n",
            "Epoch 333/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0831 - accuracy: 0.9255\n",
            "Epoch 334/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0835 - accuracy: 0.9254\n",
            "Epoch 335/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0834 - accuracy: 0.9254\n",
            "Epoch 336/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0838 - accuracy: 0.9257\n",
            "Epoch 337/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0828 - accuracy: 0.9256\n",
            "Epoch 338/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0827 - accuracy: 0.9256\n",
            "Epoch 339/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0822 - accuracy: 0.9259\n",
            "Epoch 340/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0815 - accuracy: 0.9259\n",
            "Epoch 341/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0809 - accuracy: 0.9260\n",
            "Epoch 342/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0806 - accuracy: 0.9261\n",
            "Epoch 343/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0800 - accuracy: 0.9262\n",
            "Epoch 344/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0798 - accuracy: 0.9262\n",
            "Epoch 345/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0799 - accuracy: 0.9263\n",
            "Epoch 346/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0797 - accuracy: 0.9262\n",
            "Epoch 347/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0794 - accuracy: 0.9262\n",
            "Epoch 348/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0792 - accuracy: 0.9263\n",
            "Epoch 349/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0792 - accuracy: 0.9263\n",
            "Epoch 350/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0789 - accuracy: 0.9264\n",
            "Epoch 351/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0788 - accuracy: 0.9265\n",
            "Epoch 352/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0784 - accuracy: 0.9265\n",
            "Epoch 353/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0783 - accuracy: 0.9265\n",
            "Epoch 354/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0781 - accuracy: 0.9265\n",
            "Epoch 355/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0781 - accuracy: 0.9265\n",
            "Epoch 356/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0780 - accuracy: 0.9266\n",
            "Epoch 357/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0784 - accuracy: 0.9264\n",
            "Epoch 358/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0775 - accuracy: 0.9267\n",
            "Epoch 359/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0774 - accuracy: 0.9267\n",
            "Epoch 360/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0771 - accuracy: 0.9268\n",
            "Epoch 361/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0767 - accuracy: 0.9268\n",
            "Epoch 362/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0765 - accuracy: 0.9268\n",
            "Epoch 363/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0764 - accuracy: 0.9267\n",
            "Epoch 364/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0760 - accuracy: 0.9269\n",
            "Epoch 365/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0759 - accuracy: 0.9269\n",
            "Epoch 366/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0759 - accuracy: 0.9269\n",
            "Epoch 367/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0761 - accuracy: 0.9269\n",
            "Epoch 368/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0761 - accuracy: 0.9269\n",
            "Epoch 369/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0761 - accuracy: 0.9269\n",
            "Epoch 370/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0759 - accuracy: 0.9270\n",
            "Epoch 371/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0757 - accuracy: 0.9269\n",
            "Epoch 372/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0755 - accuracy: 0.9269\n",
            "Epoch 373/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0754 - accuracy: 0.9271\n",
            "Epoch 374/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0749 - accuracy: 0.9271\n",
            "Epoch 375/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0753 - accuracy: 0.9271\n",
            "Epoch 376/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0750 - accuracy: 0.9271\n",
            "Epoch 377/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0747 - accuracy: 0.9272\n",
            "Epoch 378/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0744 - accuracy: 0.9272\n",
            "Epoch 379/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0743 - accuracy: 0.9272\n",
            "Epoch 380/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0734 - accuracy: 0.9274\n",
            "Epoch 381/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0736 - accuracy: 0.9273\n",
            "Epoch 382/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0735 - accuracy: 0.9273\n",
            "Epoch 383/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0735 - accuracy: 0.9274\n",
            "Epoch 384/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0739 - accuracy: 0.9272\n",
            "Epoch 385/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0735 - accuracy: 0.9274\n",
            "Epoch 386/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0731 - accuracy: 0.9274\n",
            "Epoch 387/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0730 - accuracy: 0.9275\n",
            "Epoch 388/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0732 - accuracy: 0.9274\n",
            "Epoch 389/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0728 - accuracy: 0.9275\n",
            "Epoch 390/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0729 - accuracy: 0.9274\n",
            "Epoch 391/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0723 - accuracy: 0.9276\n",
            "Epoch 392/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0720 - accuracy: 0.9276\n",
            "Epoch 393/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0724 - accuracy: 0.9275\n",
            "Epoch 394/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0721 - accuracy: 0.9276\n",
            "Epoch 395/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0717 - accuracy: 0.9278\n",
            "Epoch 396/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0714 - accuracy: 0.9278\n",
            "Epoch 397/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0715 - accuracy: 0.9278\n",
            "Epoch 398/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0717 - accuracy: 0.9277\n",
            "Epoch 399/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0714 - accuracy: 0.9278\n",
            "Epoch 400/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0709 - accuracy: 0.9279\n",
            "Epoch 401/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0709 - accuracy: 0.9279\n",
            "Epoch 402/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0704 - accuracy: 0.9279\n",
            "Epoch 403/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0702 - accuracy: 0.9280\n",
            "Epoch 404/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0702 - accuracy: 0.9279\n",
            "Epoch 405/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0701 - accuracy: 0.9281\n",
            "Epoch 406/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0699 - accuracy: 0.9281\n",
            "Epoch 407/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0698 - accuracy: 0.9281\n",
            "Epoch 408/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0698 - accuracy: 0.9280\n",
            "Epoch 409/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0692 - accuracy: 0.9282\n",
            "Epoch 410/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0691 - accuracy: 0.9282\n",
            "Epoch 411/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0692 - accuracy: 0.9282\n",
            "Epoch 412/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0688 - accuracy: 0.9282\n",
            "Epoch 413/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0689 - accuracy: 0.9282\n",
            "Epoch 414/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0688 - accuracy: 0.9282\n",
            "Epoch 415/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0689 - accuracy: 0.9282\n",
            "Epoch 416/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0691 - accuracy: 0.9282\n",
            "Epoch 417/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0692 - accuracy: 0.9281\n",
            "Epoch 418/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0696 - accuracy: 0.9281\n",
            "Epoch 419/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0694 - accuracy: 0.9282\n",
            "Epoch 420/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0685 - accuracy: 0.9282\n",
            "Epoch 421/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0682 - accuracy: 0.9284\n",
            "Epoch 422/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0681 - accuracy: 0.9284\n",
            "Epoch 423/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0680 - accuracy: 0.9284\n",
            "Epoch 424/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0675 - accuracy: 0.9285\n",
            "Epoch 425/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0673 - accuracy: 0.9286\n",
            "Epoch 426/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0672 - accuracy: 0.9285\n",
            "Epoch 427/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0672 - accuracy: 0.9285\n",
            "Epoch 428/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0670 - accuracy: 0.9286\n",
            "Epoch 429/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0672 - accuracy: 0.9284\n",
            "Epoch 430/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0672 - accuracy: 0.9285\n",
            "Epoch 431/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0674 - accuracy: 0.9285\n",
            "Epoch 432/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0671 - accuracy: 0.9286\n",
            "Epoch 433/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0667 - accuracy: 0.9286\n",
            "Epoch 434/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0664 - accuracy: 0.9287\n",
            "Epoch 435/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0672 - accuracy: 0.9286\n",
            "Epoch 436/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0675 - accuracy: 0.9284\n",
            "Epoch 437/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0671 - accuracy: 0.9285\n",
            "Epoch 438/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0672 - accuracy: 0.9286\n",
            "Epoch 439/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0665 - accuracy: 0.9287\n",
            "Epoch 440/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0664 - accuracy: 0.9287\n",
            "Epoch 441/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0663 - accuracy: 0.9287\n",
            "Epoch 442/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0658 - accuracy: 0.9288\n",
            "Epoch 443/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0658 - accuracy: 0.9288\n",
            "Epoch 444/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0656 - accuracy: 0.9289\n",
            "Epoch 445/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0660 - accuracy: 0.9288\n",
            "Epoch 446/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0657 - accuracy: 0.9288\n",
            "Epoch 447/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0649 - accuracy: 0.9290\n",
            "Epoch 448/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0653 - accuracy: 0.9289\n",
            "Epoch 449/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0649 - accuracy: 0.9290\n",
            "Epoch 450/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0646 - accuracy: 0.9290\n",
            "Epoch 451/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0643 - accuracy: 0.9291\n",
            "Epoch 452/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0645 - accuracy: 0.9291\n",
            "Epoch 453/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0642 - accuracy: 0.9292\n",
            "Epoch 454/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0641 - accuracy: 0.9291\n",
            "Epoch 455/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0639 - accuracy: 0.9291\n",
            "Epoch 456/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0641 - accuracy: 0.9291\n",
            "Epoch 457/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0636 - accuracy: 0.9293\n",
            "Epoch 458/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0634 - accuracy: 0.9293\n",
            "Epoch 459/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0634 - accuracy: 0.9292\n",
            "Epoch 460/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0632 - accuracy: 0.9293\n",
            "Epoch 461/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0631 - accuracy: 0.9294\n",
            "Epoch 462/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0632 - accuracy: 0.9293\n",
            "Epoch 463/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0630 - accuracy: 0.9293\n",
            "Epoch 464/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0629 - accuracy: 0.9294\n",
            "Epoch 465/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0629 - accuracy: 0.9293\n",
            "Epoch 466/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0627 - accuracy: 0.9294\n",
            "Epoch 467/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0626 - accuracy: 0.9295\n",
            "Epoch 468/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0624 - accuracy: 0.9294\n",
            "Epoch 469/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0622 - accuracy: 0.9295\n",
            "Epoch 470/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0623 - accuracy: 0.9295\n",
            "Epoch 471/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0622 - accuracy: 0.9295\n",
            "Epoch 472/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0620 - accuracy: 0.9295\n",
            "Epoch 473/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0619 - accuracy: 0.9295\n",
            "Epoch 474/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0617 - accuracy: 0.9296\n",
            "Epoch 475/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0618 - accuracy: 0.9295\n",
            "Epoch 476/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0616 - accuracy: 0.9296\n",
            "Epoch 477/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0615 - accuracy: 0.9296\n",
            "Epoch 478/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0615 - accuracy: 0.9296\n",
            "Epoch 479/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0615 - accuracy: 0.9295\n",
            "Epoch 480/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0616 - accuracy: 0.9296\n",
            "Epoch 481/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0617 - accuracy: 0.9296\n",
            "Epoch 482/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0612 - accuracy: 0.9296\n",
            "Epoch 483/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0608 - accuracy: 0.9298\n",
            "Epoch 484/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0608 - accuracy: 0.9297\n",
            "Epoch 485/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0606 - accuracy: 0.9298\n",
            "Epoch 486/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0605 - accuracy: 0.9298\n",
            "Epoch 487/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0604 - accuracy: 0.9298\n",
            "Epoch 488/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0604 - accuracy: 0.9298\n",
            "Epoch 489/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0603 - accuracy: 0.9299\n",
            "Epoch 490/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0602 - accuracy: 0.9299\n",
            "Epoch 491/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0603 - accuracy: 0.9298\n",
            "Epoch 492/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0601 - accuracy: 0.9299\n",
            "Epoch 493/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0601 - accuracy: 0.9299\n",
            "Epoch 494/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0600 - accuracy: 0.9299\n",
            "Epoch 495/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0597 - accuracy: 0.9299\n",
            "Epoch 496/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0597 - accuracy: 0.9299\n",
            "Epoch 497/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0597 - accuracy: 0.9300\n",
            "Epoch 498/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0595 - accuracy: 0.9300\n",
            "Epoch 499/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0596 - accuracy: 0.9300\n",
            "Epoch 500/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0593 - accuracy: 0.9300\n",
            "Epoch 501/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0594 - accuracy: 0.9300\n",
            "Epoch 502/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0595 - accuracy: 0.9300\n",
            "Epoch 503/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0596 - accuracy: 0.9299\n",
            "Epoch 504/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0590 - accuracy: 0.9301\n",
            "Epoch 505/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0589 - accuracy: 0.9300\n",
            "Epoch 506/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0591 - accuracy: 0.9299\n",
            "Epoch 507/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0589 - accuracy: 0.9301\n",
            "Epoch 508/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0589 - accuracy: 0.9301\n",
            "Epoch 509/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0586 - accuracy: 0.9302\n",
            "Epoch 510/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0583 - accuracy: 0.9302\n",
            "Epoch 511/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0583 - accuracy: 0.9302\n",
            "Epoch 512/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0581 - accuracy: 0.9302\n",
            "Epoch 513/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0580 - accuracy: 0.9303\n",
            "Epoch 514/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0581 - accuracy: 0.9302\n",
            "Epoch 515/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0581 - accuracy: 0.9302\n",
            "Epoch 516/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0581 - accuracy: 0.9303\n",
            "Epoch 517/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0582 - accuracy: 0.9302\n",
            "Epoch 518/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0579 - accuracy: 0.9303\n",
            "Epoch 519/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0579 - accuracy: 0.9303\n",
            "Epoch 520/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0579 - accuracy: 0.9302\n",
            "Epoch 521/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0577 - accuracy: 0.9303\n",
            "Epoch 522/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0579 - accuracy: 0.9303\n",
            "Epoch 523/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0575 - accuracy: 0.9303\n",
            "Epoch 524/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0571 - accuracy: 0.9304\n",
            "Epoch 525/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0571 - accuracy: 0.9304\n",
            "Epoch 526/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0569 - accuracy: 0.9304\n",
            "Epoch 527/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0570 - accuracy: 0.9304\n",
            "Epoch 528/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0570 - accuracy: 0.9305\n",
            "Epoch 529/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0569 - accuracy: 0.9304\n",
            "Epoch 530/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0568 - accuracy: 0.9305\n",
            "Epoch 531/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0570 - accuracy: 0.9304\n",
            "Epoch 532/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0566 - accuracy: 0.9305\n",
            "Epoch 533/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0563 - accuracy: 0.9306\n",
            "Epoch 534/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0565 - accuracy: 0.9305\n",
            "Epoch 535/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0565 - accuracy: 0.9305\n",
            "Epoch 536/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0563 - accuracy: 0.9306\n",
            "Epoch 537/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0564 - accuracy: 0.9305\n",
            "Epoch 538/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0562 - accuracy: 0.9306\n",
            "Epoch 539/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0563 - accuracy: 0.9305\n",
            "Epoch 540/1000\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.0563 - accuracy: 0.9306\n",
            "Epoch 541/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0559 - accuracy: 0.9307\n",
            "Epoch 542/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0559 - accuracy: 0.9306\n",
            "Epoch 543/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0559 - accuracy: 0.9306\n",
            "Epoch 544/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0558 - accuracy: 0.9306\n",
            "Epoch 545/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0557 - accuracy: 0.9307\n",
            "Epoch 546/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0556 - accuracy: 0.9307\n",
            "Epoch 547/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0555 - accuracy: 0.9307\n",
            "Epoch 548/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0553 - accuracy: 0.9308\n",
            "Epoch 549/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0552 - accuracy: 0.9307\n",
            "Epoch 550/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0551 - accuracy: 0.9308\n",
            "Epoch 551/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0551 - accuracy: 0.9307\n",
            "Epoch 552/1000\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.0552 - accuracy: 0.9307\n",
            "Epoch 553/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0551 - accuracy: 0.9308\n",
            "Epoch 554/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0548 - accuracy: 0.9309\n",
            "Epoch 555/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0550 - accuracy: 0.9308\n",
            "Epoch 556/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0551 - accuracy: 0.9307\n",
            "Epoch 557/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0552 - accuracy: 0.9308\n",
            "Epoch 558/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0550 - accuracy: 0.9308\n",
            "Epoch 559/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0555 - accuracy: 0.9308\n",
            "Epoch 560/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0554 - accuracy: 0.9307\n",
            "Epoch 561/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0550 - accuracy: 0.9308\n",
            "Epoch 562/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0548 - accuracy: 0.9308\n",
            "Epoch 563/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0546 - accuracy: 0.9308\n",
            "Epoch 564/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0544 - accuracy: 0.9309\n",
            "Epoch 565/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0542 - accuracy: 0.9309\n",
            "Epoch 566/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0540 - accuracy: 0.9310\n",
            "Epoch 567/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0541 - accuracy: 0.9310\n",
            "Epoch 568/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0540 - accuracy: 0.9309\n",
            "Epoch 569/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0540 - accuracy: 0.9310\n",
            "Epoch 570/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0542 - accuracy: 0.9309\n",
            "Epoch 571/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0538 - accuracy: 0.9309\n",
            "Epoch 572/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0540 - accuracy: 0.9309\n",
            "Epoch 573/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0539 - accuracy: 0.9309\n",
            "Epoch 574/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0539 - accuracy: 0.9309\n",
            "Epoch 575/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0537 - accuracy: 0.9310\n",
            "Epoch 576/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0542 - accuracy: 0.9309\n",
            "Epoch 577/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0540 - accuracy: 0.9309\n",
            "Epoch 578/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0537 - accuracy: 0.9310\n",
            "Epoch 579/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0534 - accuracy: 0.9311\n",
            "Epoch 580/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0533 - accuracy: 0.9310\n",
            "Epoch 581/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0535 - accuracy: 0.9311\n",
            "Epoch 582/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0535 - accuracy: 0.9311\n",
            "Epoch 583/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0536 - accuracy: 0.9311\n",
            "Epoch 584/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0538 - accuracy: 0.9310\n",
            "Epoch 585/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0544 - accuracy: 0.9309\n",
            "Epoch 586/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0540 - accuracy: 0.9310\n",
            "Epoch 587/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0536 - accuracy: 0.9310\n",
            "Epoch 588/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0529 - accuracy: 0.9312\n",
            "Epoch 589/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0527 - accuracy: 0.9311\n",
            "Epoch 590/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0527 - accuracy: 0.9311\n",
            "Epoch 591/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0522 - accuracy: 0.9313\n",
            "Epoch 592/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0522 - accuracy: 0.9313\n",
            "Epoch 593/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0520 - accuracy: 0.9313\n",
            "Epoch 594/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0521 - accuracy: 0.9313\n",
            "Epoch 595/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0522 - accuracy: 0.9313\n",
            "Epoch 596/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0521 - accuracy: 0.9312\n",
            "Epoch 597/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0520 - accuracy: 0.9313\n",
            "Epoch 598/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0519 - accuracy: 0.9313\n",
            "Epoch 599/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0521 - accuracy: 0.9313\n",
            "Epoch 600/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0520 - accuracy: 0.9313\n",
            "Epoch 601/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0521 - accuracy: 0.9312\n",
            "Epoch 602/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0519 - accuracy: 0.9313\n",
            "Epoch 603/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0518 - accuracy: 0.9313\n",
            "Epoch 604/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0516 - accuracy: 0.9314\n",
            "Epoch 605/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0515 - accuracy: 0.9314\n",
            "Epoch 606/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0514 - accuracy: 0.9314\n",
            "Epoch 607/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0515 - accuracy: 0.9313\n",
            "Epoch 608/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0514 - accuracy: 0.9314\n",
            "Epoch 609/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0513 - accuracy: 0.9314\n",
            "Epoch 610/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0514 - accuracy: 0.9314\n",
            "Epoch 611/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0518 - accuracy: 0.9314\n",
            "Epoch 612/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0517 - accuracy: 0.9313\n",
            "Epoch 613/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0517 - accuracy: 0.9313\n",
            "Epoch 614/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0514 - accuracy: 0.9314\n",
            "Epoch 615/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0514 - accuracy: 0.9314\n",
            "Epoch 616/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0508 - accuracy: 0.9315\n",
            "Epoch 617/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0510 - accuracy: 0.9315\n",
            "Epoch 618/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0511 - accuracy: 0.9314\n",
            "Epoch 619/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0510 - accuracy: 0.9315\n",
            "Epoch 620/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0508 - accuracy: 0.9315\n",
            "Epoch 621/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0509 - accuracy: 0.9314\n",
            "Epoch 622/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0508 - accuracy: 0.9315\n",
            "Epoch 623/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0507 - accuracy: 0.9314\n",
            "Epoch 624/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0507 - accuracy: 0.9315\n",
            "Epoch 625/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0506 - accuracy: 0.9315\n",
            "Epoch 626/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0504 - accuracy: 0.9315\n",
            "Epoch 627/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0505 - accuracy: 0.9315\n",
            "Epoch 628/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0507 - accuracy: 0.9315\n",
            "Epoch 629/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0505 - accuracy: 0.9316\n",
            "Epoch 630/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0503 - accuracy: 0.9315\n",
            "Epoch 631/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0501 - accuracy: 0.9316\n",
            "Epoch 632/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0501 - accuracy: 0.9316\n",
            "Epoch 633/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0500 - accuracy: 0.9316\n",
            "Epoch 634/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0500 - accuracy: 0.9316\n",
            "Epoch 635/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0499 - accuracy: 0.9316\n",
            "Epoch 636/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0498 - accuracy: 0.9317\n",
            "Epoch 637/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0498 - accuracy: 0.9316\n",
            "Epoch 638/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0497 - accuracy: 0.9316\n",
            "Epoch 639/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0496 - accuracy: 0.9317\n",
            "Epoch 640/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0496 - accuracy: 0.9316\n",
            "Epoch 641/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0496 - accuracy: 0.9316\n",
            "Epoch 642/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0495 - accuracy: 0.9317\n",
            "Epoch 643/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0496 - accuracy: 0.9317\n",
            "Epoch 644/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0494 - accuracy: 0.9318\n",
            "Epoch 645/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0493 - accuracy: 0.9317\n",
            "Epoch 646/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0494 - accuracy: 0.9317\n",
            "Epoch 647/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0494 - accuracy: 0.9317\n",
            "Epoch 648/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0494 - accuracy: 0.9317\n",
            "Epoch 649/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0492 - accuracy: 0.9318\n",
            "Epoch 650/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0490 - accuracy: 0.9317\n",
            "Epoch 651/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0491 - accuracy: 0.9318\n",
            "Epoch 652/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0489 - accuracy: 0.9317\n",
            "Epoch 653/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0492 - accuracy: 0.9317\n",
            "Epoch 654/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0490 - accuracy: 0.9317\n",
            "Epoch 655/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0491 - accuracy: 0.9317\n",
            "Epoch 656/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0490 - accuracy: 0.9317\n",
            "Epoch 657/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0492 - accuracy: 0.9317\n",
            "Epoch 658/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0486 - accuracy: 0.9318\n",
            "Epoch 659/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0487 - accuracy: 0.9318\n",
            "Epoch 660/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0487 - accuracy: 0.9318\n",
            "Epoch 661/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0487 - accuracy: 0.9318\n",
            "Epoch 662/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0487 - accuracy: 0.9318\n",
            "Epoch 663/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0489 - accuracy: 0.9318\n",
            "Epoch 664/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0489 - accuracy: 0.9318\n",
            "Epoch 665/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0488 - accuracy: 0.9318\n",
            "Epoch 666/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0484 - accuracy: 0.9319\n",
            "Epoch 667/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0486 - accuracy: 0.9318\n",
            "Epoch 668/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0484 - accuracy: 0.9319\n",
            "Epoch 669/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0482 - accuracy: 0.9319\n",
            "Epoch 670/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0483 - accuracy: 0.9318\n",
            "Epoch 671/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0482 - accuracy: 0.9319\n",
            "Epoch 672/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0482 - accuracy: 0.9319\n",
            "Epoch 673/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0482 - accuracy: 0.9319\n",
            "Epoch 674/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0482 - accuracy: 0.9319\n",
            "Epoch 675/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0479 - accuracy: 0.9319\n",
            "Epoch 676/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0481 - accuracy: 0.9319\n",
            "Epoch 677/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0481 - accuracy: 0.9319\n",
            "Epoch 678/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0479 - accuracy: 0.9319\n",
            "Epoch 679/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0479 - accuracy: 0.9319\n",
            "Epoch 680/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0478 - accuracy: 0.9320\n",
            "Epoch 681/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0478 - accuracy: 0.9319\n",
            "Epoch 682/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0480 - accuracy: 0.9319\n",
            "Epoch 683/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0479 - accuracy: 0.9319\n",
            "Epoch 684/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0478 - accuracy: 0.9319\n",
            "Epoch 685/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0480 - accuracy: 0.9319\n",
            "Epoch 686/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0482 - accuracy: 0.9319\n",
            "Epoch 687/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0481 - accuracy: 0.9319\n",
            "Epoch 688/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0479 - accuracy: 0.9319\n",
            "Epoch 689/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0481 - accuracy: 0.9319\n",
            "Epoch 690/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0478 - accuracy: 0.9319\n",
            "Epoch 691/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0474 - accuracy: 0.9320\n",
            "Epoch 692/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0474 - accuracy: 0.9320\n",
            "Epoch 693/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0471 - accuracy: 0.9320\n",
            "Epoch 694/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0472 - accuracy: 0.9320\n",
            "Epoch 695/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0473 - accuracy: 0.9320\n",
            "Epoch 696/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0472 - accuracy: 0.9320\n",
            "Epoch 697/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0470 - accuracy: 0.9320\n",
            "Epoch 698/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0471 - accuracy: 0.9321\n",
            "Epoch 699/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0469 - accuracy: 0.9320\n",
            "Epoch 700/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0470 - accuracy: 0.9321\n",
            "Epoch 701/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0468 - accuracy: 0.9321\n",
            "Epoch 702/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0469 - accuracy: 0.9321\n",
            "Epoch 703/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0469 - accuracy: 0.9321\n",
            "Epoch 704/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0468 - accuracy: 0.9321\n",
            "Epoch 705/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0468 - accuracy: 0.9321\n",
            "Epoch 706/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0467 - accuracy: 0.9320\n",
            "Epoch 707/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0467 - accuracy: 0.9321\n",
            "Epoch 708/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0468 - accuracy: 0.9320\n",
            "Epoch 709/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0469 - accuracy: 0.9321\n",
            "Epoch 710/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0470 - accuracy: 0.9320\n",
            "Epoch 711/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0472 - accuracy: 0.9320\n",
            "Epoch 712/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0470 - accuracy: 0.9320\n",
            "Epoch 713/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0470 - accuracy: 0.9320\n",
            "Epoch 714/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0469 - accuracy: 0.9321\n",
            "Epoch 715/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0467 - accuracy: 0.9321\n",
            "Epoch 716/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0465 - accuracy: 0.9321\n",
            "Epoch 717/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0464 - accuracy: 0.9321\n",
            "Epoch 718/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0464 - accuracy: 0.9321\n",
            "Epoch 719/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0463 - accuracy: 0.9321\n",
            "Epoch 720/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 721/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0465 - accuracy: 0.9321\n",
            "Epoch 722/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 723/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0463 - accuracy: 0.9321\n",
            "Epoch 724/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0461 - accuracy: 0.9322\n",
            "Epoch 725/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 726/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0461 - accuracy: 0.9321\n",
            "Epoch 727/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0460 - accuracy: 0.9321\n",
            "Epoch 728/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0461 - accuracy: 0.9321\n",
            "Epoch 729/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0461 - accuracy: 0.9322\n",
            "Epoch 730/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0463 - accuracy: 0.9321\n",
            "Epoch 731/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0464 - accuracy: 0.9321\n",
            "Epoch 732/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 733/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0464 - accuracy: 0.9321\n",
            "Epoch 734/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0461 - accuracy: 0.9321\n",
            "Epoch 735/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 736/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0464 - accuracy: 0.9321\n",
            "Epoch 737/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 738/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 739/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0462 - accuracy: 0.9321\n",
            "Epoch 740/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0461 - accuracy: 0.9321\n",
            "Epoch 741/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0460 - accuracy: 0.9322\n",
            "Epoch 742/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0461 - accuracy: 0.9322\n",
            "Epoch 743/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0458 - accuracy: 0.9322\n",
            "Epoch 744/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0457 - accuracy: 0.9322\n",
            "Epoch 745/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0456 - accuracy: 0.9322\n",
            "Epoch 746/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0455 - accuracy: 0.9322\n",
            "Epoch 747/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0454 - accuracy: 0.9322\n",
            "Epoch 748/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0453 - accuracy: 0.9323\n",
            "Epoch 749/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0453 - accuracy: 0.9322\n",
            "Epoch 750/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0455 - accuracy: 0.9322\n",
            "Epoch 751/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0454 - accuracy: 0.9322\n",
            "Epoch 752/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0454 - accuracy: 0.9322\n",
            "Epoch 753/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0450 - accuracy: 0.9323\n",
            "Epoch 754/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0452 - accuracy: 0.9323\n",
            "Epoch 755/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0454 - accuracy: 0.9322\n",
            "Epoch 756/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0456 - accuracy: 0.9322\n",
            "Epoch 757/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0455 - accuracy: 0.9322\n",
            "Epoch 758/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0453 - accuracy: 0.9323\n",
            "Epoch 759/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0451 - accuracy: 0.9323\n",
            "Epoch 760/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0451 - accuracy: 0.9322\n",
            "Epoch 761/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0450 - accuracy: 0.9323\n",
            "Epoch 762/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0451 - accuracy: 0.9323\n",
            "Epoch 763/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0450 - accuracy: 0.9323\n",
            "Epoch 764/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0449 - accuracy: 0.9323\n",
            "Epoch 765/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0449 - accuracy: 0.9323\n",
            "Epoch 766/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0449 - accuracy: 0.9323\n",
            "Epoch 767/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0448 - accuracy: 0.9323\n",
            "Epoch 768/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0448 - accuracy: 0.9323\n",
            "Epoch 769/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0448 - accuracy: 0.9323\n",
            "Epoch 770/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 771/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 772/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 773/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 774/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 775/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0446 - accuracy: 0.9323\n",
            "Epoch 776/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0446 - accuracy: 0.9323\n",
            "Epoch 777/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 778/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0446 - accuracy: 0.9323\n",
            "Epoch 779/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0446 - accuracy: 0.9323\n",
            "Epoch 780/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0445 - accuracy: 0.9323\n",
            "Epoch 781/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0443 - accuracy: 0.9323\n",
            "Epoch 782/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0445 - accuracy: 0.9323\n",
            "Epoch 783/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0443 - accuracy: 0.9324\n",
            "Epoch 784/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0443 - accuracy: 0.9324\n",
            "Epoch 785/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 786/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0444 - accuracy: 0.9323\n",
            "Epoch 787/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0443 - accuracy: 0.9323\n",
            "Epoch 788/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0441 - accuracy: 0.9324\n",
            "Epoch 789/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 790/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 791/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 792/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0441 - accuracy: 0.9323\n",
            "Epoch 793/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0441 - accuracy: 0.9324\n",
            "Epoch 794/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 795/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0440 - accuracy: 0.9324\n",
            "Epoch 796/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0441 - accuracy: 0.9324\n",
            "Epoch 797/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 798/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0440 - accuracy: 0.9324\n",
            "Epoch 799/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0442 - accuracy: 0.9324\n",
            "Epoch 800/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0440 - accuracy: 0.9324\n",
            "Epoch 801/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0441 - accuracy: 0.9323\n",
            "Epoch 802/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0440 - accuracy: 0.9324\n",
            "Epoch 803/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0444 - accuracy: 0.9323\n",
            "Epoch 804/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 805/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0450 - accuracy: 0.9323\n",
            "Epoch 806/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0451 - accuracy: 0.9322\n",
            "Epoch 807/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0450 - accuracy: 0.9323\n",
            "Epoch 808/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0445 - accuracy: 0.9323\n",
            "Epoch 809/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0445 - accuracy: 0.9323\n",
            "Epoch 810/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 811/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0442 - accuracy: 0.9324\n",
            "Epoch 812/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0442 - accuracy: 0.9323\n",
            "Epoch 813/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0438 - accuracy: 0.9324\n",
            "Epoch 814/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0440 - accuracy: 0.9324\n",
            "Epoch 815/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0437 - accuracy: 0.9324\n",
            "Epoch 816/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0437 - accuracy: 0.9324\n",
            "Epoch 817/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0437 - accuracy: 0.9324\n",
            "Epoch 818/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0435 - accuracy: 0.9324\n",
            "Epoch 819/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0435 - accuracy: 0.9324\n",
            "Epoch 820/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0435 - accuracy: 0.9324\n",
            "Epoch 821/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0435 - accuracy: 0.9324\n",
            "Epoch 822/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 823/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0434 - accuracy: 0.9324\n",
            "Epoch 824/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 825/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 826/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0434 - accuracy: 0.9324\n",
            "Epoch 827/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0434 - accuracy: 0.9324\n",
            "Epoch 828/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 829/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0436 - accuracy: 0.9324\n",
            "Epoch 830/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0435 - accuracy: 0.9324\n",
            "Epoch 831/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 832/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 833/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 834/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 835/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0434 - accuracy: 0.9324\n",
            "Epoch 836/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0438 - accuracy: 0.9324\n",
            "Epoch 837/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0446 - accuracy: 0.9323\n",
            "Epoch 838/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0447 - accuracy: 0.9323\n",
            "Epoch 839/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0445 - accuracy: 0.9323\n",
            "Epoch 840/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0446 - accuracy: 0.9323\n",
            "Epoch 841/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0448 - accuracy: 0.9324\n",
            "Epoch 842/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0448 - accuracy: 0.9323\n",
            "Epoch 843/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0442 - accuracy: 0.9324\n",
            "Epoch 844/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0438 - accuracy: 0.9324\n",
            "Epoch 845/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0436 - accuracy: 0.9324\n",
            "Epoch 846/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0437 - accuracy: 0.9324\n",
            "Epoch 847/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0434 - accuracy: 0.9324\n",
            "Epoch 848/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0433 - accuracy: 0.9324\n",
            "Epoch 849/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0430 - accuracy: 0.9324\n",
            "Epoch 850/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0429 - accuracy: 0.9324\n",
            "Epoch 851/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0429 - accuracy: 0.9325\n",
            "Epoch 852/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0429 - accuracy: 0.9325\n",
            "Epoch 853/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0428 - accuracy: 0.9324\n",
            "Epoch 854/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0427 - accuracy: 0.9325\n",
            "Epoch 855/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0428 - accuracy: 0.9325\n",
            "Epoch 856/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0428 - accuracy: 0.9325\n",
            "Epoch 857/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0428 - accuracy: 0.9325\n",
            "Epoch 858/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0429 - accuracy: 0.9325\n",
            "Epoch 859/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0428 - accuracy: 0.9325\n",
            "Epoch 860/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0428 - accuracy: 0.9324\n",
            "Epoch 861/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0429 - accuracy: 0.9324\n",
            "Epoch 862/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0428 - accuracy: 0.9325\n",
            "Epoch 863/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0427 - accuracy: 0.9325\n",
            "Epoch 864/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 865/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0426 - accuracy: 0.9325\n",
            "Epoch 866/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 867/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 868/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 869/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0426 - accuracy: 0.9325\n",
            "Epoch 870/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 871/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 872/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0424 - accuracy: 0.9325\n",
            "Epoch 873/1000\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 874/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0424 - accuracy: 0.9325\n",
            "Epoch 875/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 876/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 877/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0425 - accuracy: 0.9325\n",
            "Epoch 878/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0424 - accuracy: 0.9325\n",
            "Epoch 879/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0424 - accuracy: 0.9325\n",
            "Epoch 880/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 881/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0424 - accuracy: 0.9325\n",
            "Epoch 882/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 883/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 884/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 885/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 886/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 887/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 888/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 889/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 890/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 891/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 892/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 893/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 894/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 895/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 896/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 897/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 898/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 899/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 900/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 901/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 902/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 903/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 904/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 905/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 906/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 907/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 908/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 909/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 910/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0424 - accuracy: 0.9325\n",
            "Epoch 911/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0423 - accuracy: 0.9325\n",
            "Epoch 912/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0421 - accuracy: 0.9325\n",
            "Epoch 913/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0422 - accuracy: 0.9325\n",
            "Epoch 914/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0420 - accuracy: 0.9325\n",
            "Epoch 915/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0418 - accuracy: 0.9325\n",
            "Epoch 916/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 917/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0418 - accuracy: 0.9325\n",
            "Epoch 918/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0418 - accuracy: 0.9325\n",
            "Epoch 919/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0419 - accuracy: 0.9325\n",
            "Epoch 920/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0419 - accuracy: 0.9325\n",
            "Epoch 921/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0418 - accuracy: 0.9325\n",
            "Epoch 922/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 923/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 924/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 925/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 926/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 927/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0418 - accuracy: 0.9325\n",
            "Epoch 928/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 929/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 930/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0417 - accuracy: 0.9325\n",
            "Epoch 931/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0418 - accuracy: 0.9325\n",
            "Epoch 932/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 933/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 934/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 935/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 936/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 937/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 938/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 939/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 940/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 941/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 942/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 943/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 944/1000\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 945/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 946/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 947/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 948/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 949/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 950/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 951/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 952/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 953/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 954/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 955/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0414 - accuracy: 0.9326\n",
            "Epoch 956/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 957/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 958/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 959/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0412 - accuracy: 0.9325\n",
            "Epoch 960/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 961/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9326\n",
            "Epoch 962/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0414 - accuracy: 0.9326\n",
            "Epoch 963/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 964/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0412 - accuracy: 0.9325\n",
            "Epoch 965/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0415 - accuracy: 0.9325\n",
            "Epoch 966/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0416 - accuracy: 0.9325\n",
            "Epoch 967/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0413 - accuracy: 0.9326\n",
            "Epoch 968/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 969/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0412 - accuracy: 0.9325\n",
            "Epoch 970/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0412 - accuracy: 0.9326\n",
            "Epoch 971/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 972/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 973/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0413 - accuracy: 0.9326\n",
            "Epoch 974/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0411 - accuracy: 0.9326\n",
            "Epoch 975/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0411 - accuracy: 0.9326\n",
            "Epoch 976/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0411 - accuracy: 0.9326\n",
            "Epoch 977/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0409 - accuracy: 0.9326\n",
            "Epoch 978/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 979/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0411 - accuracy: 0.9326\n",
            "Epoch 980/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0412 - accuracy: 0.9325\n",
            "Epoch 981/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 982/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 983/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0409 - accuracy: 0.9326\n",
            "Epoch 984/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0411 - accuracy: 0.9326\n",
            "Epoch 985/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 986/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0412 - accuracy: 0.9325\n",
            "Epoch 987/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 988/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 989/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0409 - accuracy: 0.9326\n",
            "Epoch 990/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0412 - accuracy: 0.9326\n",
            "Epoch 991/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 992/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0412 - accuracy: 0.9326\n",
            "Epoch 993/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0413 - accuracy: 0.9325\n",
            "Epoch 994/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0414 - accuracy: 0.9325\n",
            "Epoch 995/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 996/1000\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.0408 - accuracy: 0.9326\n",
            "Epoch 997/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 998/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0410 - accuracy: 0.9326\n",
            "Epoch 999/1000\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.0408 - accuracy: 0.9326\n",
            "Epoch 1000/1000\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.0408 - accuracy: 0.9326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1bc0cae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOLSYGYdnO-E"
      },
      "source": [
        "test_images_loc='/content/DRIVE/test/test/images'\n",
        "\n",
        "test_files= os.listdir(test_images_loc)\n",
        "test_files.sort()\n",
        "test_data=[]\n",
        "for i in test_files:\n",
        "  test_im= plt.imread('/content/DRIVE/test/test/images/' + i)\n",
        "  test_data.append(cv2.resize(test_im,(desired_size, desired_size)))\n",
        "\n",
        "test_data= np.array(test_data)\n",
        "x_test = test_data/ 255.\n",
        "x_test = np.reshape(x_test, (len(x_test), desired_size, desired_size, 3))  # adapt this if using `channels_first` image data format\n",
        "y_pred= model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V4mtlsXryBc",
        "outputId": "ef900c51-db27-4efa-a3e8-f2e7aa9e0060"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 256, 256, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmQwdE1loIYX",
        "outputId": "dff86d9b-794a-4c99-8550-94e30c52f886"
      },
      "source": [
        "test_files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['01_test.tif',\n",
              " '02_test.tif',\n",
              " '03_test.tif',\n",
              " '04_test.tif',\n",
              " '05_test.tif',\n",
              " '06_test.tif',\n",
              " '07_test.tif',\n",
              " '08_test.tif',\n",
              " '09_test.tif',\n",
              " '10_test.tif',\n",
              " '11_test.tif',\n",
              " '12_test.tif',\n",
              " '13_test.tif',\n",
              " '14_test.tif',\n",
              " '15_test.tif',\n",
              " '16_test.tif',\n",
              " '17_test.tif',\n",
              " '18_test.tif',\n",
              " '19_test.tif',\n",
              " '20_test.tif']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "8vM0tgXbkqmL",
        "outputId": "eedfa76f-5792-4455-86f0-2c2f3c25f8d1"
      },
      "source": [
        "from PIL import Image \n",
        "i=1\n",
        "for img in y_pred:\n",
        "  #arr= np.array(img)\n",
        "  img= np.reshape(img, (256,256))\n",
        "  #img= Image.fromarray(arr)\n",
        "  plt.imshow(img*255, cmap=\"gray\")\n",
        "  path=\"/content/results1/test_\"+ str(i) + \".jpg\"\n",
        "  cv2.imwrite(str(path),img*255)                    # img*255 is important for cv2 to save the image properly.\n",
        "  i= i+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRtoedDW_Qwc"
      },
      "source": [
        "## **Model 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBRJqQOYhJzr"
      },
      "source": [
        "  \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, concatenate\n",
        "\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "conv1 =    Dropout(0.2)(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "conv2 =    Dropout(0.2)(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "drop4 = Dropout(0.5)(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(pool4))\n",
        "merge6 = concatenate([drop4,up6], axis = 3)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "merge7 = concatenate([conv3,up7], axis = 3)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "merge8 = concatenate([conv2,up8], axis = 3)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "merge9 = concatenate([conv1,up9], axis = 3)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "model.compile(optimizer = Adam(0.01), loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiFd5SaZ9puI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14aad9c8-db5e-4183-d028-c6676e248bde"
      },
      "source": [
        "model.fit( x_train, y_train, steps_per_epoch=100, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "100/100 [==============================] - 9s 80ms/step - loss: 65122995273728.0000 - accuracy: 0.8795\n",
            "Epoch 2/1000\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2701 - accuracy: 0.8795\n",
            "Epoch 3/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2691 - accuracy: 0.8795\n",
            "Epoch 4/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2670 - accuracy: 0.8795\n",
            "Epoch 5/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2659 - accuracy: 0.8795\n",
            "Epoch 6/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2648 - accuracy: 0.8795\n",
            "Epoch 7/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2643 - accuracy: 0.8795\n",
            "Epoch 8/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2630 - accuracy: 0.8795\n",
            "Epoch 9/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2623 - accuracy: 0.8795\n",
            "Epoch 10/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2619 - accuracy: 0.8795\n",
            "Epoch 11/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2615 - accuracy: 0.8795\n",
            "Epoch 12/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2614 - accuracy: 0.8795\n",
            "Epoch 13/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2612 - accuracy: 0.8795\n",
            "Epoch 14/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2610 - accuracy: 0.8795\n",
            "Epoch 15/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2607 - accuracy: 0.8795\n",
            "Epoch 16/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2606 - accuracy: 0.8795\n",
            "Epoch 17/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2606 - accuracy: 0.8795\n",
            "Epoch 18/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2605 - accuracy: 0.8795\n",
            "Epoch 19/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2605 - accuracy: 0.8795\n",
            "Epoch 20/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2605 - accuracy: 0.8795\n",
            "Epoch 21/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2605 - accuracy: 0.8795\n",
            "Epoch 22/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2603 - accuracy: 0.8795\n",
            "Epoch 23/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2604 - accuracy: 0.8795\n",
            "Epoch 24/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2605 - accuracy: 0.8795\n",
            "Epoch 25/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2604 - accuracy: 0.8795\n",
            "Epoch 26/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2600 - accuracy: 0.8795\n",
            "Epoch 27/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2604 - accuracy: 0.8795\n",
            "Epoch 28/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2601 - accuracy: 0.8795\n",
            "Epoch 29/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2597 - accuracy: 0.8795\n",
            "Epoch 30/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2596 - accuracy: 0.8795\n",
            "Epoch 31/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2588 - accuracy: 0.8795\n",
            "Epoch 32/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2590 - accuracy: 0.8795\n",
            "Epoch 33/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2588 - accuracy: 0.8795\n",
            "Epoch 34/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2591 - accuracy: 0.8795\n",
            "Epoch 35/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2585 - accuracy: 0.8795\n",
            "Epoch 36/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2581 - accuracy: 0.8795\n",
            "Epoch 37/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2577 - accuracy: 0.8795\n",
            "Epoch 38/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2573 - accuracy: 0.8795\n",
            "Epoch 39/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2572 - accuracy: 0.8795\n",
            "Epoch 40/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2566 - accuracy: 0.8795\n",
            "Epoch 41/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2608 - accuracy: 0.8795\n",
            "Epoch 42/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2604 - accuracy: 0.8795\n",
            "Epoch 43/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2593 - accuracy: 0.8795\n",
            "Epoch 44/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2569 - accuracy: 0.8795\n",
            "Epoch 45/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2560 - accuracy: 0.8795\n",
            "Epoch 46/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2557 - accuracy: 0.8795\n",
            "Epoch 47/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2551 - accuracy: 0.8795\n",
            "Epoch 48/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2551 - accuracy: 0.8795\n",
            "Epoch 49/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2551 - accuracy: 0.8795\n",
            "Epoch 50/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2518 - accuracy: 0.8795\n",
            "Epoch 51/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2529 - accuracy: 0.8795\n",
            "Epoch 52/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2523 - accuracy: 0.8795\n",
            "Epoch 53/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2508 - accuracy: 0.8795\n",
            "Epoch 54/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2499 - accuracy: 0.8795\n",
            "Epoch 55/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2513 - accuracy: 0.8795\n",
            "Epoch 56/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2493 - accuracy: 0.8795\n",
            "Epoch 57/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2493 - accuracy: 0.8795\n",
            "Epoch 58/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2491 - accuracy: 0.8795\n",
            "Epoch 59/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2472 - accuracy: 0.8795\n",
            "Epoch 60/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2460 - accuracy: 0.8795\n",
            "Epoch 61/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2481 - accuracy: 0.8795\n",
            "Epoch 62/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2490 - accuracy: 0.8795\n",
            "Epoch 63/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2460 - accuracy: 0.8795\n",
            "Epoch 64/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2472 - accuracy: 0.8795\n",
            "Epoch 65/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2455 - accuracy: 0.8795\n",
            "Epoch 66/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2459 - accuracy: 0.8795\n",
            "Epoch 67/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2461 - accuracy: 0.8795\n",
            "Epoch 68/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2444 - accuracy: 0.8795\n",
            "Epoch 69/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2446 - accuracy: 0.8795\n",
            "Epoch 70/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2443 - accuracy: 0.8795\n",
            "Epoch 71/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2440 - accuracy: 0.8795\n",
            "Epoch 72/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2439 - accuracy: 0.8795\n",
            "Epoch 73/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2445 - accuracy: 0.8795\n",
            "Epoch 74/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2441 - accuracy: 0.8795\n",
            "Epoch 75/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2439 - accuracy: 0.8795\n",
            "Epoch 76/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2430 - accuracy: 0.8795\n",
            "Epoch 77/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2434 - accuracy: 0.8795\n",
            "Epoch 78/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2435 - accuracy: 0.8795\n",
            "Epoch 79/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2423 - accuracy: 0.8795\n",
            "Epoch 80/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2448 - accuracy: 0.8795\n",
            "Epoch 81/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2429 - accuracy: 0.8795\n",
            "Epoch 82/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2431 - accuracy: 0.8795\n",
            "Epoch 83/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2425 - accuracy: 0.8795\n",
            "Epoch 84/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2421 - accuracy: 0.8795\n",
            "Epoch 85/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2435 - accuracy: 0.8795\n",
            "Epoch 86/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2435 - accuracy: 0.8795\n",
            "Epoch 87/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2453 - accuracy: 0.8795\n",
            "Epoch 88/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2437 - accuracy: 0.8795\n",
            "Epoch 89/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2438 - accuracy: 0.8795\n",
            "Epoch 90/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2424 - accuracy: 0.8795\n",
            "Epoch 91/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2430 - accuracy: 0.8795\n",
            "Epoch 92/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2425 - accuracy: 0.8795\n",
            "Epoch 93/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2453 - accuracy: 0.8795\n",
            "Epoch 94/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2443 - accuracy: 0.8795\n",
            "Epoch 95/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2437 - accuracy: 0.8795\n",
            "Epoch 96/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2427 - accuracy: 0.8795\n",
            "Epoch 97/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2431 - accuracy: 0.8795\n",
            "Epoch 98/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2433 - accuracy: 0.8795\n",
            "Epoch 99/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2437 - accuracy: 0.8795\n",
            "Epoch 100/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2430 - accuracy: 0.8795\n",
            "Epoch 101/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2439 - accuracy: 0.8795\n",
            "Epoch 102/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2447 - accuracy: 0.8795\n",
            "Epoch 103/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2438 - accuracy: 0.8795\n",
            "Epoch 104/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2431 - accuracy: 0.8795\n",
            "Epoch 105/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2427 - accuracy: 0.8795\n",
            "Epoch 106/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2425 - accuracy: 0.8795\n",
            "Epoch 107/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2430 - accuracy: 0.8795\n",
            "Epoch 108/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2423 - accuracy: 0.8795\n",
            "Epoch 109/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2432 - accuracy: 0.8795\n",
            "Epoch 110/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2458 - accuracy: 0.8795\n",
            "Epoch 111/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2454 - accuracy: 0.8795\n",
            "Epoch 112/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2455 - accuracy: 0.8795\n",
            "Epoch 113/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2448 - accuracy: 0.8795\n",
            "Epoch 114/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2436 - accuracy: 0.8795\n",
            "Epoch 115/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2446 - accuracy: 0.8795\n",
            "Epoch 116/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2440 - accuracy: 0.8795\n",
            "Epoch 117/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2444 - accuracy: 0.8795\n",
            "Epoch 118/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2485 - accuracy: 0.8795\n",
            "Epoch 119/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2442 - accuracy: 0.8795\n",
            "Epoch 120/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2450 - accuracy: 0.8795\n",
            "Epoch 121/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2434 - accuracy: 0.8795\n",
            "Epoch 122/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2450 - accuracy: 0.8795\n",
            "Epoch 123/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2432 - accuracy: 0.8795\n",
            "Epoch 124/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2436 - accuracy: 0.8795\n",
            "Epoch 125/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2452 - accuracy: 0.8795\n",
            "Epoch 126/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2429 - accuracy: 0.8795\n",
            "Epoch 127/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2431 - accuracy: 0.8795\n",
            "Epoch 128/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2445 - accuracy: 0.8795\n",
            "Epoch 129/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2439 - accuracy: 0.8795\n",
            "Epoch 130/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2431 - accuracy: 0.8795\n",
            "Epoch 131/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2436 - accuracy: 0.8795\n",
            "Epoch 132/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2422 - accuracy: 0.8795\n",
            "Epoch 133/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2429 - accuracy: 0.8795\n",
            "Epoch 134/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2427 - accuracy: 0.8795\n",
            "Epoch 135/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2428 - accuracy: 0.8795\n",
            "Epoch 136/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2426 - accuracy: 0.8795\n",
            "Epoch 137/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2412 - accuracy: 0.8795\n",
            "Epoch 138/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2424 - accuracy: 0.8795\n",
            "Epoch 139/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2434 - accuracy: 0.8795\n",
            "Epoch 140/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2413 - accuracy: 0.8795\n",
            "Epoch 141/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2415 - accuracy: 0.8795\n",
            "Epoch 142/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2415 - accuracy: 0.8795\n",
            "Epoch 143/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2416 - accuracy: 0.8795\n",
            "Epoch 144/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2421 - accuracy: 0.8795\n",
            "Epoch 145/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2430 - accuracy: 0.8795\n",
            "Epoch 146/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2435 - accuracy: 0.8795\n",
            "Epoch 147/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2418 - accuracy: 0.8795\n",
            "Epoch 148/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2418 - accuracy: 0.8795\n",
            "Epoch 149/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2426 - accuracy: 0.8795\n",
            "Epoch 150/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2417 - accuracy: 0.8795\n",
            "Epoch 151/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2421 - accuracy: 0.8795\n",
            "Epoch 152/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2412 - accuracy: 0.8795\n",
            "Epoch 153/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2437 - accuracy: 0.8795\n",
            "Epoch 154/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2421 - accuracy: 0.8795\n",
            "Epoch 155/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2430 - accuracy: 0.8795\n",
            "Epoch 156/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2423 - accuracy: 0.8795\n",
            "Epoch 157/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2411 - accuracy: 0.8795\n",
            "Epoch 158/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2429 - accuracy: 0.8795\n",
            "Epoch 159/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2435 - accuracy: 0.8795\n",
            "Epoch 160/1000\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2442 - accuracy: 0.8795\n",
            "Epoch 161/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2437 - accuracy: 0.8795\n",
            "Epoch 162/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2431 - accuracy: 0.8795\n",
            "Epoch 163/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2443 - accuracy: 0.8795\n",
            "Epoch 164/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2438 - accuracy: 0.8795\n",
            "Epoch 165/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2433 - accuracy: 0.8795\n",
            "Epoch 166/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2432 - accuracy: 0.8795\n",
            "Epoch 167/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2421 - accuracy: 0.8795\n",
            "Epoch 168/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2428 - accuracy: 0.8795\n",
            "Epoch 169/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2439 - accuracy: 0.8795\n",
            "Epoch 170/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2426 - accuracy: 0.8795\n",
            "Epoch 171/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2432 - accuracy: 0.8795\n",
            "Epoch 172/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2422 - accuracy: 0.8795\n",
            "Epoch 173/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2437 - accuracy: 0.8795\n",
            "Epoch 174/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2430 - accuracy: 0.8795\n",
            "Epoch 175/1000\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2439 - accuracy: 0.8795\n",
            "Epoch 176/1000\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 0.2437 - accuracy: 0.8798"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cd7bd787eceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkcoXecp-t-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}