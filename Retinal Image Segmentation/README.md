# Description of the Files:
* [SAU-Net.ipynb](https://github.com/SOUMEE2000/Machine-Learning-Stash/blob/main/Retinal%20Image%20Segmentation/1.SA_UNet.ipynb): This contains an implementation of the [**Spatial Attention U-Net paper**](https://arxiv.org/ftp/arxiv/papers/2004/2004.03696.pdf). The model has been tried on the DRIVE Dataset with upto 92% accuracy. This is basically an attention based Convolutional Neural Network model. It is a derivative of the conventional U-net model already in use. Various data augmentation strategies have been used. The images of the test set formed therof are also present in the respective folders. 
**Areas of improvement**: data augmentation strategies, use of dropblock to be done properly.
* [Nearest_Neighbour_Algorithms_on_pixelwise_classification_of_DRIVE.ipynb](https://github.com/SOUMEE2000/Machine-Learning-Stash/blob/main/Retinal%20Image%20Segmentation/2.Nearest_Neighbour_Algorithms_on_pixelwise_classification_of_DRIVE.ipynb): KNN is performed on pixelwise classification of Retinal images of the DRIVE Dataset, considering the RGB channels only. Random undersampling and oversampling is done to fix the ratio of non blood vessel pixels and blood vessel pixels which are originally in the ratio of 1:10. SMOTE algorithm followed by random undersampling of the over-used classes is done, bringing the ratio of blood vessel pixels to non-blood vessel pixels to 1:5.
